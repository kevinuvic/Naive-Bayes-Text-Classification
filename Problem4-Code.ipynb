{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Implementation of Multinomial Model (Naive Bayes Document Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on traindata.txt/trainlabels.txt, \n",
      "\t accuracy= 96.58 %\n",
      "\n",
      "Test on testdata.txt/testlabels.txt, \n",
      "\t accuracy= 80.2 %\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Sep 29, 2019\n",
    "\n",
    "This is the solution to Problem 4 of the assignment 1 of \n",
    "    DATA MINING course, CSC 503\n",
    "\n",
    "@author: Jian Wang (V00935999)\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "'''------------------------------\n",
    "#\n",
    "# Preprocess 1: Read data from 2 pairs of text file (train_data.txt, test_data.txt)\n",
    "#\n",
    "---------------------------------'''\n",
    "def read_data_from_files():\n",
    "    traindata_file = open('traindata.txt')\n",
    "    trainlabel_file = open('trainlabels.txt')\n",
    "    testdata_file = open('testdata.txt')\n",
    "    testlabel_file = open('testlabels.txt')\n",
    "    \n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    \n",
    "    for line in traindata_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        train_data.append(line)\n",
    "        \n",
    "    for line in trainlabel_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        train_label.append(int(line))\n",
    "    \n",
    "    for line in testdata_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        test_data.append(line)\n",
    "    \n",
    "    for line in testlabel_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        test_label.append(int(line))\n",
    "        \n",
    "    return (train_data, train_label, test_data, test_label)\n",
    "\n",
    "'''------------------------------\n",
    "#\n",
    "# Preprocess 2: Extract train vocabulary\n",
    "#\n",
    "---------------------------------'''\n",
    "def extract_vocab(train_data):\n",
    "    \n",
    "    vocabulary = []\n",
    "    \n",
    "    for line in train_data:\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split(' ')\n",
    "        for word in line:\n",
    "            if word not in vocabulary and len(word) > 0:\n",
    "                vocabulary.append(word)\n",
    "    vocabulary.sort()\n",
    "    return vocabulary\n",
    "\n",
    "'''------------------------------\n",
    "#\n",
    "# Preprocess 3: Convert data/label into DataFrame under column of vocabulary \n",
    "#\n",
    "#        Convert array[1 dimensional] to dataframe[2 dimensional table]\n",
    "#        Column: vocab, Row: doc_index, Cell: vocab count in a document\n",
    "#\n",
    "---------------------------------'''\n",
    "def preprocess(vocabulary, train_data, train_label, test_data, test_label):\n",
    "    \n",
    "    train_x = np.zeros((len(train_data), len(vocabulary)))\n",
    "    test_x = np.zeros((len(test_data), len(vocabulary)))\n",
    "    \n",
    "    train_count = 0\n",
    "    \n",
    "    for line in train_data:\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split(' ')\n",
    "        for word in line:\n",
    "            if word in vocabulary:\n",
    "                index = vocabulary.index(word)\n",
    "                train_x[train_count][index] += 1\n",
    "                \n",
    "        train_count += 1\n",
    "        \n",
    "    test_count = 0\n",
    "    \n",
    "    for line in test_data:\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split(' ')\n",
    "        for word in line:\n",
    "            if word in vocabulary:\n",
    "                index = vocabulary.index(word)\n",
    "                test_x[test_count][index] += 1\n",
    "                \n",
    "        test_count += 1\n",
    "    \n",
    "    train_y = list(map(int, train_label))\n",
    "    test_y = list(map(int, test_label))\n",
    "    \n",
    "    train_x = pd.DataFrame(train_x, columns = vocabulary)\n",
    "    test_x = pd.DataFrame(test_x, columns = vocabulary)\n",
    "    \n",
    "    train_y = pd.DataFrame(train_y, columns = ['label'])\n",
    "    test_y =  pd.DataFrame(test_y, columns = ['label'])\n",
    "    \n",
    "    return (train_x, train_y, test_x, test_y)\n",
    "\n",
    "'''------------------------------\n",
    "#\n",
    "# Main: Entry of classifier\n",
    "#\n",
    "---------------------------------'''\n",
    "def NaiveBayesTextClassification():\n",
    "    \n",
    "    '''---------------------------------\n",
    "        Part 1: Preprocess\n",
    "    '''\n",
    "    (train_docs, train_class, test_docs, test_class) = read_data_from_files()\n",
    "    \n",
    "    vocabulary = extract_vocab(train_docs)\n",
    "    \n",
    "    (train_DOCS, train_CLASS,\n",
    "     test_DOCS, test_CLASS) = preprocess(vocabulary, \n",
    "                                     train_docs, train_class, \n",
    "                                     test_docs, test_class)\n",
    "    \n",
    "    '''---------------------------------\n",
    "        Part 2: Train the classifier with train data\n",
    "    '''\n",
    "    (prior, condprob, classlist) = TrainMultinomialNB(train_CLASS, \n",
    "                                   train_DOCS, vocabulary)\n",
    "    \n",
    "    '''---------------------------------\n",
    "        Part 3: Run with the test data 1\n",
    "    '''\n",
    "    result = ApplyMultinomialNB_OnDocs(classlist, vocabulary, prior, condprob, train_docs)\n",
    "    accuracy = calculate_accuracy(result, train_class)\n",
    "    print(\"Test on traindata.txt/trainlabels.txt, \\n\\t accuracy=\", accuracy, \"%\\n\")\n",
    "    \n",
    "    #\n",
    "    #    Run with the test data 2\n",
    "    #\n",
    "    result = ApplyMultinomialNB_OnDocs(classlist, vocabulary, prior, condprob, test_docs)\n",
    "    accuracy = calculate_accuracy(result, test_class)\n",
    "    print(\"Test on testdata.txt/testlabels.txt, \\n\\t accuracy=\", accuracy, \"%\")\n",
    "\n",
    "#\n",
    "# Main, utility function: calculate the accuracy \n",
    "#\n",
    "def calculate_accuracy(result_label, test_label):\n",
    "        rst = np.asarray(result_label)\n",
    "        tst = np.asarray(test_label)\n",
    "\n",
    "        count = np.equal(rst, tst)\n",
    "        value, count = np.unique(count, return_counts = True)\n",
    "        val_count = dict(zip(value, count))\n",
    "        \n",
    "        try :\n",
    "            accuracy = 1 - (val_count[False] / rst.shape[0])\n",
    "        except KeyError:\n",
    "            accuracy = 1\n",
    "        \n",
    "        return round(accuracy*100, 2)\n",
    "\n",
    "\n",
    "'''------------------------------\n",
    "#\n",
    "# Body 1: Train the classifier,\n",
    "#\n",
    "#        To refer to Pseudocode of the algorithm for more info about\n",
    "#        the calculation of prior, condprob, which on Slide 14(Naive Bayes for Text Classification)\n",
    "#        of Course Presentation\n",
    "#\n",
    "#        @CLASS_DF: Class in form of DataFrame ()\n",
    "---------------------------------'''\n",
    "def TrainMultinomialNB(CLASS_DF, DOCS, VOCAB):\n",
    "    \n",
    "    condprob = {}\n",
    "    prior = {}\n",
    "    countdocs = DOCS.shape[0]  #len(DOCS)\n",
    "    \n",
    "    clsval = CLASS_DF.columns.values\n",
    "    clslist, clscount = np.unique(CLASS_DF[clsval], return_counts = True)\n",
    "    count_DocInClass = dict(zip(clslist, clscount))\n",
    "    for clsIdx, docCnt in count_DocInClass.items():\n",
    "        prior[clsIdx] = count_DocInClass[clsIdx] / countdocs\n",
    "        \n",
    "    clscount = len(clscount)\n",
    "    vocabcount = len(VOCAB)\n",
    "    docscount = len(DOCS)\n",
    "    \n",
    "    #conditional probability\n",
    "    condprob = np.zeros((clscount, vocabcount))\n",
    "    \n",
    "    #occurrence of a token in a term\n",
    "    Token_CT = np.zeros((clscount, vocabcount))\n",
    "    \n",
    "    \n",
    "    #Traverse all documents, Rows of Docs\n",
    "    for i in range(docscount):\n",
    "        cls_idx = CLASS_DF.iloc[i, 0]\n",
    "        for k in range(vocabcount):\n",
    "            # CountTokenOfTerm(text_class, token)\n",
    "            Token_CT[cls_idx, k] += DOCS.iloc[i,k]\n",
    "    \n",
    "    sum_Token_CT = np.zeros(clscount)\n",
    "    for cls in range(clscount) : \n",
    "        for k in range(vocabcount):\n",
    "            sum_Token_CT[cls] += Token_CT[cls, k]\n",
    "\n",
    "    for cls in range(clscount) : \n",
    "        for k in range(vocabcount):\n",
    "            # get conditional probability\n",
    "            condprob[cls, k] = ((Token_CT[cls,k] + 1)\n",
    "                    / (sum_Token_CT[cls] + Token_CT[cls,k] + 1))\n",
    "    \n",
    "    return (prior, condprob, clslist)\n",
    "\n",
    "'''------------------------------\n",
    "#\n",
    "# Body 2: Apply classification on a group of documents\n",
    "#\n",
    "---------------------------------'''\n",
    "def ApplyMultinomialNB_OnDocs(classlist, VOCAB, prior, condprob, docs):\n",
    "    classify_result = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        classify_result.append(\n",
    "            ApplyMultinomialNB(classlist, VOCAB, prior, condprob, doc))\n",
    "    \n",
    "    return classify_result\n",
    "\n",
    "#\n",
    "# Body 2, utility function: Apply classifier on a document\n",
    "#\n",
    "#        To refer to Pseudocode of the algorithm for more info about\n",
    "#        the calculation of score\n",
    "#\n",
    "def ApplyMultinomialNB(classlist, VOCAB, prior, condprob, doc):\n",
    "    \n",
    "    w_vocab = ExtractTokenFromDoc(VOCAB, doc)\n",
    "    \n",
    "    score = []\n",
    "    for c in classlist:\n",
    "        score.append(1 * np.log2(prior[c]))\n",
    "        \n",
    "        for t in w_vocab:\n",
    "            # \n",
    "            idx = VOCAB.index(t)\n",
    "            score[c] += 1 * np.log2(condprob[c, idx])\n",
    "            \n",
    "    return np.argmax(score)\n",
    "\n",
    "# \n",
    "# Body 2, utility function: extract token from the test document\n",
    "#\n",
    "def ExtractTokenFromDoc(train_VOCAB, test_doc):\n",
    "    w_vocab = []\n",
    "\n",
    "    \n",
    "    test_doc = test_doc.replace('\\n', '')\n",
    "    line = test_doc.split(' ')\n",
    "    for word in line:\n",
    "        if word in train_VOCAB and len(word) > 0 and word not in w_vocab:\n",
    "            w_vocab.append(word)\n",
    "            \n",
    "    w_vocab.sort()\n",
    "    \n",
    "    return w_vocab\n",
    "\n",
    "#def (documents):\n",
    "#    vocab = preprocess_vocab(documents)\n",
    "#    return vocab\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesTextClassification()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
